{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Add your name here\n",
        "#Name: Ilyas Khaja"
      ],
      "metadata": {
        "id": "4YW3011Ja3IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDPdFXW70zNQ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For this programs we are going to evaluate the ID3 on three different datasets:\n",
        "#Change the path based on your directory address \n",
        "path=\"/content/gdrive/MyDrive/CS412/hw1/\"\n",
        "\n",
        "\n",
        "#for agaricus we don't have a separate validation set, so we are going to reuse the training set.\n",
        "agaricus = [\"agaricus/agaricuslepiotatrain1.csv\",\n",
        "              \"agaricus/agaricuslepiotatrain1.csv\",\n",
        "              \"agaricus/agaricuslepiotatest1.csv\"]\n",
        "\n",
        "dataset1 = [\"data_sets1/training_set.csv\",\n",
        "            \"data_sets1/validation_set.csv\",\n",
        "            \"data_sets1/test_set.csv\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "1Nc5a9ekK0gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from a file. It returns a list of data points as well as the list of variable names\n",
        "def read_data(filename):\n",
        "    f = open(filename, 'r')\n",
        "    p = re.compile(',')\n",
        "    data = []\n",
        "    header = f.readline().strip()\n",
        "    varnames = p.split(header)\n",
        "    namehash = {}\n",
        "    for l in f:\n",
        "        data.append([int(x) for x in p.split(l.strip())])\n",
        "    return (data, varnames)"
      ],
      "metadata": {
        "id": "2PgoiWmwLpJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = agaricus\n",
        "train_data, varnames = read_data(path+dataset[0])\n",
        "#the last element in the list is the class value.\""
      ],
      "metadata": {
        "id": "gj6DCp5BLqAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bFhQSHB0zNQ"
      },
      "outputs": [],
      "source": [
        "#Here we have the neccessary data structure and auxilary functions for construcing the decision trees\n",
        "#You don't need to modify the codes in this cell\n",
        "class Node:\n",
        "    \"\"\" Node class for a decision tree. \"\"\"\n",
        "    #var is the variable name for the node\n",
        "    def __init__(self, var):\n",
        "        self.var = var\n",
        "\n",
        "    def classify(x):\n",
        "        \"\"\" Handled by the subclasses. \"\"\"\n",
        "        return None\n",
        "\n",
        "    def dump(self, indent):\n",
        "        \"\"\" Handled by the subclasses. \"\"\"\n",
        "        return None\n",
        "\n",
        "\n",
        "class Leaf(Node):\n",
        "    #value is the label of the leaf node\n",
        "    def __init__(self, value):\n",
        "        Node.__init__(self, None);\n",
        "        self.value = value\n",
        "\n",
        "    def classify(self, x):\n",
        "        return self.value\n",
        "\n",
        "    def dump(self, indent):\n",
        "        print(' %d' % self.value)\n",
        "\n",
        "\n",
        "class Split(Node):\n",
        "    #var: the variable that we create the split on\n",
        "    #left and right are the branches for each side which are Nodes\n",
        "    def __init__(self, var, left, right):\n",
        "        Node.__init__(self, var)\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "    def classify(self, x):\n",
        "        if x[self.var] == 0:\n",
        "            return self.left.classify(x)\n",
        "        else:\n",
        "            return self.right.classify(x)\n",
        "    \n",
        "    #use to print out the tree recursively\n",
        "    def dump(self, indent):\n",
        "        if indent > 0:\n",
        "            print('')\n",
        "        for i in range(0, indent):\n",
        "            print('| ', end='')\n",
        "        print('%s = 0 :' % self.var,end='')\n",
        "        self.left.dump(indent+1)\n",
        "        for i in range(0, indent):\n",
        "            print('| ', end='')\n",
        "        print('%s = 1 :' % self.var,end='')\n",
        "        self.right.dump(indent+1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcxhw-P90zNR"
      },
      "source": [
        "Helper function computes entropy of Bernoulli distribution with parameter p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig1XyQlc0zNS"
      },
      "outputs": [],
      "source": [
        "def entropy(p):\n",
        "  # >>>> YOUR CODE GOES HERE <<<<\n",
        "  if (p == 1 or p == 0):\n",
        "     return 0\n",
        "\n",
        "  return -1 * ((p * np.log2(p)) + ((1-p) * np.log2(1-p)))\n",
        "  # For now, always return \"0\":\n",
        "\n",
        "entropy(6/7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIwRPjZ0zNS"
      },
      "source": [
        "Compute information gain for a particular split, given the counts \n",
        "\n",
        "ny_nxi : number of occurences of y=1 with x_i=1 for all i=1 to n (#y=1 $\\wedge$ #xi =1)\n",
        "(n is number of variables and each variable is binary)\n",
        "\n",
        "nxi : number of occurrences of x_i=1 (#x_i)\n",
        "\n",
        "ny : number of ocurrences of y=1\n",
        "\n",
        "total: total number instances in this branch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EzR0ni-0zNS"
      },
      "outputs": [],
      "source": [
        "def infogain(ny_nxi, nxi, ny, total): #x_i = attribute, y = classification\n",
        "    # >>>> YOUR CODE GOES HERE <<<<\n",
        "\n",
        "    \n",
        "    entropy_s = entropy(ny / total) #overall entropy\n",
        "\n",
        "    entropy_sv1 = 0 if ( nxi == 0) else entropy(ny_nxi / nxi) #entropy for x_i = 1\n",
        "\n",
        "    nxi_0 = total - nxi #number of occurences of x_i = 0\n",
        "\n",
        "    ny_nxi_0 = ny - ny_nxi #number of occurences of y = 1 with x_i = 0\n",
        "\n",
        "    entropy_sv0 = 0 if (nxi_0 == 0) else entropy(ny_nxi_0 / nxi_0)\n",
        "\n",
        "    return entropy_s - (((nxi / total) * (entropy_sv1)) + ((nxi_0 / total) * (entropy_sv0)))\n",
        "    # For now, always return \"0\":\n",
        "\n",
        "#infogain(6, 8, 9, 14)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split_df: the portion of the dataframe that routed to the current branch\n",
        "\n",
        "\n",
        "def select_attr(split_df): #calculate infogain by iterating thorugh remaining attributes, select max \n",
        "  #>>> YOUR CODE GOES HERE <<< \n",
        "  #get infogan from first attribute\n",
        "  max_attr = split_df.columns[0]\n",
        "  classLabel = split_df.columns[-1]\n",
        "\n",
        "  ny_nxi = ((split_df[max_attr] == 1) & (split_df[classLabel] == 1)).sum()\n",
        "  nxi = (split_df[max_attr] == 1).sum()\n",
        "  ny = (split_df[classLabel] == 1).sum()\n",
        "  total = split_df.shape[0]\n",
        "\n",
        "  max_gain = infogain(ny_nxi, nxi, ny, total)\n",
        "\n",
        "  cols = split_df.shape[1]\n",
        "  for i in range(1, cols-1): #iterate until poisonous col\n",
        "    attr = split_df.columns[i]\n",
        "\n",
        "    ny_nxi = ((split_df[attr] == 1) & (split_df[classLabel] == 1)).sum()\n",
        "    nxi = (split_df[attr] == 1).sum()\n",
        "    ny = (split_df[classLabel] == 1).sum()\n",
        "    total = split_df.shape[0]\n",
        "\n",
        "    gain = infogain(ny_nxi, nxi, ny, total)\n",
        "    #print(\"attribute =\", attr, \"calculated gain = \", gain)\n",
        "\n",
        "    if (gain > max_gain):\n",
        "      max_attr = attr\n",
        "      max_gain = gain \n",
        "\n",
        "  return (max_attr, max_gain)"
      ],
      "metadata": {
        "id": "njH854QyQlE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyOID_H10zNS"
      },
      "source": [
        "Build tree in a top-down manner, selecting splits until we hit a pure leaf or all splits look bad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpliyHmx0zNT"
      },
      "outputs": [],
      "source": [
        "#Recursive function for building the tree. Note that the vanilla ID3 stops when the nodes are pure (base condition for the recursion);\n",
        "#config is potential dictionary of hyperparams that you can tune over validation dataset\n",
        "#For potential list of hyperparams check here:\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
        "\n",
        "def helper(data, prev_attr):\n",
        "  (selected_attr, gain) = select_attr(data)\n",
        "  classLabel = data.columns[-1]\n",
        "\n",
        " # print(\"in helper function, prev_attr= \", prev_attr, \"selected _attr =\", selected_attr, \" and gain= \", gain)\n",
        "\n",
        "  if gain == 0: #base case, there is no gain to be made by splitting further, stop recursion\n",
        "    if (data[classLabel]).sum() > 0: #all examples are positive\n",
        "      #print(\"returning poisonous leaf: attribute =\", prev_attr, \" total samples: \", (data['poisonous']).sum())\n",
        "      return Leaf(1)\n",
        "    else:\n",
        "      #print(\"returning non-poisonous leaf: attribute =\", prev_attr, \" total samples: \", data.shape[0] - (data['poisonous']).sum())\n",
        "      return Leaf(0)\n",
        "\n",
        "  #partition data according to attribute selected\n",
        "  d1 = data[(data[selected_attr] == 1)]\n",
        "  d2 = data[(data[selected_attr] == 0)]\n",
        "\n",
        "  d1.drop(columns=selected_attr)\n",
        "  d2.drop(columns=selected_attr)\n",
        "\n",
        "  n1 = helper(d1, selected_attr)\n",
        "  n2 = helper(d2, selected_attr)\n",
        "\n",
        "  if (n1.classify == 0): #left branch\n",
        "    return Split(selected_attr, n1, n2)\n",
        "  else:\n",
        "    return Split(selected_attr, n2, n1)\n",
        "\n",
        "\n",
        "  #node = Split(selected_attr, helper(d1, selected_attr), helper(d2, selected_attr))\n",
        "  #return node\n",
        "\n",
        "def build_tree(data, config = {}):\n",
        "    # >>>> YOUR CODE GOES HERE <<<<\n",
        "    # For now, always return a leaf predicting \"1\":\n",
        "    #select first attribute\n",
        "    (selected_attr, gain) = select_attr(data)\n",
        "    #print(selected_attr, gain)\n",
        "\n",
        "    #partition data according to attribute selected\n",
        "    d1 = data[(data[selected_attr] == 1)]\n",
        "    d2 = data[(data[selected_attr] == 0)]\n",
        "\n",
        "    d1.drop(columns=selected_attr)\n",
        "    d2.drop(columns=selected_attr)\n",
        "\n",
        "    n1 = helper(d1, selected_attr)\n",
        "    n2 = helper(d2, selected_attr)\n",
        "\n",
        "    if (n1.classify == 0): #left branch\n",
        "      return Split(selected_attr, n1, n2)\n",
        "    else:\n",
        "      return Split(selected_attr, n2, n1)\n",
        "\n",
        "   # root = Split(selected_attr, helper(d1, selected_attr), helper(d2, selected_attr))\n",
        "    \n",
        "    #return root\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-3leu0F0zNU"
      },
      "source": [
        "Build the decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKuEGLKC0zNU"
      },
      "outputs": [],
      "source": [
        "model = build_tree(data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn7yEAIQ0zNU"
      },
      "outputs": [],
      "source": [
        "model.dump(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W32-R9Jv0zNU"
      },
      "source": [
        "Calcuating the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assume the last column in the class label and returns one dataframe for labels and one for attributes\n",
        "def separate_attributes_label(data):\n",
        "  class_column = data.columns[-1]\n",
        "  xdata = data.drop(columns=class_column);\n",
        "  ydata = data[class_column];\n",
        "  return xdata, ydata"
      ],
      "metadata": {
        "id": "11m-VN-kpR9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, ytrain = separate_attributes_label(data_df);"
      ],
      "metadata": {
        "id": "JYxQIvhk6yT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JbQUxVW0zNU"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, xdata, ydata):\n",
        "  correct = 0.0;\n",
        "  for i in range(xdata.shape[0]):\n",
        "    if model.classify(xdata.loc[i]) == ydata.loc[i]:\n",
        "     # print(\"correctly classified \", xdata.loc[i], \" = \", ydata.loc[i])\n",
        "      correct += 1;\n",
        "  return correct / xdata.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h3JQGZ60zNU"
      },
      "outputs": [],
      "source": [
        "print(\"Train Accuracy: {}\".format(accuracy(model, xtrain, ytrain)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfRwygFy7OUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have all pieces working we can automate the training for any given dataset"
      ],
      "metadata": {
        "id": "5MP068F87Ons"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU-phgcx0zNU"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataset, config={}):\n",
        "  train = pd.read_csv(path+dataset[0])\n",
        "  val = pd.read_csv(path+dataset[1]) \n",
        "  test = pd.read_csv(path+dataset[2]) \n",
        "\n",
        "  xtrain, ytrain = separate_attributes_label(train);\n",
        "  xval, yval = separate_attributes_label(val);\n",
        "  xtest, ytest = separate_attributes_label(test);\n",
        "\n",
        "  model = build_tree(train, config)\n",
        "  model.dump(0)\n",
        "\n",
        "  print(\"Train Accuracy: {}\".format(accuracy(model, xtrain, ytrain)))\n",
        "  print(\"Val Accuracy: {}\".format(accuracy(model, xval, yval)))\n",
        "  print(\"Test Accuracy: {}\".format(accuracy(model, xtest, ytest)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(agaricus)"
      ],
      "metadata": {
        "id": "ORHmRYtwTWh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config={'min_example': 2}\n",
        "evaluate(dataset1, config)"
      ],
      "metadata": {
        "id": "sX9SycY_2Btt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}